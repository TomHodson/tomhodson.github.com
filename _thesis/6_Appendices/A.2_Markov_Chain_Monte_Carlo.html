---
title: Markov Chain Monte Carlo
excerpt: 
layout: none
image: 

---
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Markov Chain Monte Carlo</title>


<script src="/assets/mathjax/tex-mml-svg.js" id="MathJax-script" async></script>
<script src="/assets/js/thesis_scrollspy.js"></script>

<link rel="stylesheet" href="/assets/css/styles.css">
<script src="/assets/js/index.js"></script>
</head>
<body>

<!--Capture the table of contents from pandoc as a jekyll variable  -->
{% capture tableOfContents %}
<br>
<nav aria-label="Table of Contents" class="page-table-of-contents">
<ul>
<li><a href="#markov-chain-monte-carlo"
id="toc-markov-chain-monte-carlo">Markov Chain Monte Carlo</a>
<ul>
<li><a href="#direct-random-sampling"
id="toc-direct-random-sampling">Direct Random Sampling</a></li>
<li><a href="#mcmc-sampling" id="toc-mcmc-sampling">MCMC
Sampling</a></li>
<li><a href="#implementation-of-mcmc"
id="toc-implementation-of-mcmc">Implementation of MCMC</a></li>
<li><a href="#global-and-detailed-balance-equations"
id="toc-global-and-detailed-balance-equations">Global and Detailed
balance equations</a></li>
<li><a href="#the-metropolis-hastings-algorithm"
id="toc-the-metropolis-hastings-algorithm">The Metropolis-Hastings
Algorithm</a></li>
<li><a href="#implementation-of-the-mh-algorithm"
id="toc-implementation-of-the-mh-algorithm">Implementation of the MH
Algorithm</a></li>
<li><a href="#the-metropolis-hasting-algorithm"
id="toc-the-metropolis-hasting-algorithm">The Metropolis-Hasting
Algorithm</a></li>
<li><a href="#metropolis-hastings"
id="toc-metropolis-hastings">Metropolis-Hastings</a>
<ul>
<li><a href="#the-metropolis-hastings-algorithm-1"
id="toc-the-metropolis-hastings-algorithm-1">The Metropolis-Hastings
Algorithm</a></li>
</ul></li>
<li><a href="#two-step-trick" id="toc-two-step-trick">Two Step
Trick</a></li>
<li><a href="#detailed-balance-for-the-two-step-method"
id="toc-detailed-balance-for-the-two-step-method">Detailed Balance for
the two step method</a>
<ul>
<li><a href="#two-step-trick-1" id="toc-two-step-trick-1">Two Step
Trick</a></li>
<li><a href="#auto-correlation-time"
id="toc-auto-correlation-time">Auto-correlation Time</a></li>
<li><a href="#tuning-the-proposal-distribution"
id="toc-tuning-the-proposal-distribution">Tuning the proposal
distribution</a></li>
</ul></li>
<li><a href="#proposal-distributions"
id="toc-proposal-distributions">Proposal Distributions</a></li>
<li><a href="#choosing-the-proposal-distribution"
id="toc-choosing-the-proposal-distribution">Choosing the proposal
distribution</a></li>
<li><a href="#perturbation-mcmc" id="toc-perturbation-mcmc">Perturbation
MCMC</a>
<ul>
<li><a href="#convergence-time" id="toc-convergence-time">Convergence
Time</a></li>
</ul></li>
</ul></li>
<li><a href="#appbalance-detailed-balance"
id="toc-appbalance-detailed-balance"><span id="app:balance"
label="app:balance">[app:balance]</span> DETAILED BALANCE</a></li>
<li><a href="#bibliography" id="toc-bibliography">Bibliography</a></li>
</ul>
</nav>
{% endcapture %}

<!-- Give the table of contents to header as a variable so it can be put into the sidebar-->
{% include header.html extra=tableOfContents %}

<main>

<!-- Table of Contents -->
<!-- <nav id="TOC" role="doc-toc">
<ul>
<li><a href="#markov-chain-monte-carlo"
id="toc-markov-chain-monte-carlo">Markov Chain Monte Carlo</a>
<ul>
<li><a href="#direct-random-sampling"
id="toc-direct-random-sampling">Direct Random Sampling</a></li>
<li><a href="#mcmc-sampling" id="toc-mcmc-sampling">MCMC
Sampling</a></li>
<li><a href="#implementation-of-mcmc"
id="toc-implementation-of-mcmc">Implementation of MCMC</a></li>
<li><a href="#global-and-detailed-balance-equations"
id="toc-global-and-detailed-balance-equations">Global and Detailed
balance equations</a></li>
<li><a href="#the-metropolis-hastings-algorithm"
id="toc-the-metropolis-hastings-algorithm">The Metropolis-Hastings
Algorithm</a></li>
<li><a href="#implementation-of-the-mh-algorithm"
id="toc-implementation-of-the-mh-algorithm">Implementation of the MH
Algorithm</a></li>
<li><a href="#the-metropolis-hasting-algorithm"
id="toc-the-metropolis-hasting-algorithm">The Metropolis-Hasting
Algorithm</a></li>
<li><a href="#metropolis-hastings"
id="toc-metropolis-hastings">Metropolis-Hastings</a>
<ul>
<li><a href="#the-metropolis-hastings-algorithm-1"
id="toc-the-metropolis-hastings-algorithm-1">The Metropolis-Hastings
Algorithm</a></li>
</ul></li>
<li><a href="#two-step-trick" id="toc-two-step-trick">Two Step
Trick</a></li>
<li><a href="#detailed-balance-for-the-two-step-method"
id="toc-detailed-balance-for-the-two-step-method">Detailed Balance for
the two step method</a>
<ul>
<li><a href="#two-step-trick-1" id="toc-two-step-trick-1">Two Step
Trick</a></li>
<li><a href="#auto-correlation-time"
id="toc-auto-correlation-time">Auto-correlation Time</a></li>
<li><a href="#tuning-the-proposal-distribution"
id="toc-tuning-the-proposal-distribution">Tuning the proposal
distribution</a></li>
</ul></li>
<li><a href="#proposal-distributions"
id="toc-proposal-distributions">Proposal Distributions</a></li>
<li><a href="#choosing-the-proposal-distribution"
id="toc-choosing-the-proposal-distribution">Choosing the proposal
distribution</a></li>
<li><a href="#perturbation-mcmc" id="toc-perturbation-mcmc">Perturbation
MCMC</a>
<ul>
<li><a href="#convergence-time" id="toc-convergence-time">Convergence
Time</a></li>
</ul></li>
</ul></li>
<li><a href="#appbalance-detailed-balance"
id="toc-appbalance-detailed-balance"><span id="app:balance"
label="app:balance">[app:balance]</span> DETAILED BALANCE</a></li>
<li><a href="#bibliography" id="toc-bibliography">Bibliography</a></li>
</ul>
</nav>
 -->

<!-- Main Page Body -->
<section id="markov-chain-monte-carlo" class="level1">
<h1>Markov Chain Monte Carlo</h1>
<p>Markov Chain Monte Carlo (MCMC) is a useful method whenever we have a
probability distribution that we want to sample from but there is not
direct sampling way to do so.</p>
<section id="direct-random-sampling" class="level2">
<h2>Direct Random Sampling</h2>
<p>In almost any computer simulation the ultimate source of randomness
is a stream of (close to) uniform, uncorrelated bits generated from a
pseudo random number generator. A direct sampling method takes such a
source and outputs uncorrelated samples from the target distribution.
The fact they’re uncorrelated is key as we’ll see later. Examples of
direct sampling methods range from the trivial: take n random bits to
generate integers uniformly between 0 and <span
class="math inline">\(2^n\)</span> to more complex methods such as
inverse transform sampling and rejection sampling <span class="citation"
data-cites="devroyeRandomSampling1986"> [<a
href="#ref-devroyeRandomSampling1986"
role="doc-biblioref">1</a>]</span>.</p>
<p>In physics the distribution we usually want to sample from is the
Boltzmann probability over states of the system <span
class="math inline">\(S\)</span>: <span class="math display">\[
\begin{aligned}
p(S)  &amp;= \frac{1}{\mathcal{Z}} e^{-\beta H(S)} \\
\end{aligned}
\]</span> where <span class="math inline">\(\mathcal{Z} = \sum_S
e^{-\beta H(S)}\)</span> is the normalisation factor and ubiquitous
partition function. In principle we could directly sample from this, for
a discrete system there are finitely many choices. We could calculate
the probability of each one and assign each a region of the unit
interval which we could then sample uniformly from.</p>
<p>However if we actually try to do this we will run into two problems,
we can’t calculate <span class="math inline">\(\mathcal{Z}\)</span> for
any reasonably sized systems because the state space grows exponentially
with system size. Even if we could calculate <span
class="math inline">\(\mathcal{Z}\)</span>, sampling from an
exponentially large number of options quickly become tricky. This kind
of problem happens in many other disciplines too, particularly when
fitting statistical models using Bayesian inference <span
class="citation" data-cites="BMCP2021"> [<a href="#ref-BMCP2021"
role="doc-biblioref">2</a>]</span>.</p>
</section>
<section id="mcmc-sampling" class="level2">
<h2>MCMC Sampling</h2>
<p>So what can we do? Well it turns out that if we’re willing to give up
in the requirement that the samples be uncorrelated then we can use MCMC
instead.</p>
<p>MCMC defines a weighted random walk over the states <span
class="math inline">\((S_0, S_1, S_2, ...)\)</span>, such that in the
long time limit, states are visited according to their probability <span
class="math inline">\(p(S)\)</span>. <span class="citation"
data-cites="binderGuidePracticalWork1988 kerteszAdvancesComputerSimulation1998 wolffMonteCarloErrors2004"> [<a
href="#ref-binderGuidePracticalWork1988" role="doc-biblioref">3</a>–<a
href="#ref-wolffMonteCarloErrors2004"
role="doc-biblioref">5</a>]</span>.  <span class="citation"
data-cites="krauthIntroductionMonteCarlo1998"> [<a
href="#ref-krauthIntroductionMonteCarlo1998"
role="doc-biblioref">6</a>]</span></p>
<p><span class="math display">\[\lim_{i\to\infty} p(S_i) =
P(S)\]</span></p>
<p>In a physics context this lets us evaluate any observable with a mean
over the states visited by the walk. <span
class="math display">\[\begin{aligned}
\langle O \rangle &amp; = \sum_{S} p(S) \langle O \rangle_{S} = \sum_{i
= 0}^{M} \langle O\rangle_{S_i} + \mathcal{O}(\tfrac{1}{\sqrt{M}})\\
\end{aligned}\]</span></p>
<p>The the samples in the random walk are correlated so the samples
effectively contain less information than <span
class="math inline">\(N\)</span> independent samples would. As a
consequence the variance is larger than the <span
class="math inline">\(\langle O^2 \rangle - \langle O\rangle^2\)</span>
form it would have if the estimates were uncorrelated. Methods of
estimating the true variance of <span class="math inline">\(\langle O
\rangle\)</span> and decided how many steps are needed will be
considered later.</p>
</section>
<section id="implementation-of-mcmc" class="level2">
<h2>Implementation of MCMC</h2>
<p>In implementation MCMC can be boiled down to choosing a transition
function $(S_{t} S_{t+1}) $ where <span class="math inline">\(S\)</span>
are vectors representing classical spin configurations. We start in some
initial state <span class="math inline">\(S_0\)</span> and then
repeatedly jump to new states according to the probabilities given by
<span class="math inline">\(\mathcal{T}\)</span>. This defines a set of
random walks <span class="math inline">\(\{S_0\ldots S_i\ldots
S_N\}\)</span>.</p>
<p>In pseudo-code one could write the MCMC simulation for a single
walker as:</p>
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>current_state <span class="op">=</span> initial_state</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_steps):</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    new_state <span class="op">=</span> sample_T(current_state) </span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    states[i] <span class="op">=</span> current_state</span></code></pre></div>
<p>Where the <code>sample_T</code> function samples directly from the
transition function <span
class="math inline">\(\mathcal{T}\)</span>.</p>
<p>If we run many such walkers in parallel we can then approximate the
distribution <span class="math inline">\(p_t(S; S)\)</span> which tells
us where the walkers are likely to be after they’ve evolved for <span
class="math inline">\(t\)</span> steps from an initial state <span
class="math inline">\(S_0\)</span>. We need to carefully choose <span
class="math inline">\(\mathcal{T}\)</span> such that the the probability
<span class="math inline">\(p_t(S; S_0)\)</span> approaches the
distribution of interest. In this case the thermal distribution <span
class="math inline">\(P(S; \beta) = \mathcal{Z}^{-1} e^{-\beta
F(S)}\)</span>.</p>
</section>
<section id="global-and-detailed-balance-equations" class="level2">
<h2>Global and Detailed balance equations</h2>
<p>We cam quite easily write down the properties that <span
class="math inline">\(\mathcal{T}\)</span> must have in order to yield
the correct target distribution. Since we must transition somewhere at
each step, we first have the normalisation condition that <span
class="math display">\[\sum\limits_S \mathcal{T}(S&#39; \rightarrow S) =
1.\]</span></p>
<p>Second, let us move to an ensemble view, where rather than individual
walkers and states, we think about the probability distribution of many
walkers at each step. If we start all the walkers in the same place the
initial distribution will be a delta function and as we step the walkers
will wander around, giving us a sequence of probability distributions
<span class="math inline">\(\{p_0(S), p_1(S), p_2(S)\ldots\}\)</span>.
For discrete spaces we can write the action of the transition function
on <span class="math inline">\(p_i\)</span> as a matrix equation</p>
<p><span class="math display">\[\begin{aligned}
p_{i+1}(S) &amp;= \sum_{S&#39; \in \{S\}} p_i(S&#39;) \mathcal{T}(S&#39;
\rightarrow S)
\end{aligned}\]</span></p>
<p>This equation is essentially just stating that total probability mass
is conserved as our walkers flow around the state space.</p>
<p>In order that <span class="math inline">\(p_i\)</span> converges to
our target distribution <span class="math inline">\(p\)</span> in the
long time limit, we need the target distribution to be a fixed point of
the transition function</p>
<p><span class="math display">\[\begin{aligned}
P(S) &amp;= \sum_{S&#39;} P(S&#39;) \mathcal{T}(S&#39; \rightarrow S)
\end{aligned}
\]</span> Along with some more technical considerations such as
ergodicity which won’t be considered here, global balance suffices to
ensure that a MCMC method is correct <span class="citation"
data-cites="kellyReversibilityStochasticNetworks1981"> [<a
href="#ref-kellyReversibilityStochasticNetworks1981"
role="doc-biblioref">7</a>]</span>.</p>
<p>A sufficient but not necessary condition for global balance to hold
is called detailed balance:</p>
<p><span class="math display">\[
P(S) \mathcal{T}(S \rightarrow S&#39;) = P(S&#39;) \mathcal{T}(S&#39;
\rightarrow S)
\]</span></p>
<p>In practice most algorithms are constructed to satisfy detailed
rather than global balance, though there are arguments that the relaxed
requirements of global balance can lead to faster algorithms <span
class="citation" data-cites="kapferSamplingPolytopeHarddisk2013"> [<a
href="#ref-kapferSamplingPolytopeHarddisk2013"
role="doc-biblioref">8</a>]</span>.</p>
<p>The goal of MCMC is then to choose <span
class="math inline">\(\mathcal{T}\)</span> so that it has the desired
thermal distribution <span class="math inline">\(P(S)\)</span> as its
fixed point and converges quickly onto it. This boils down to requiring
that the matrix representation of <span class="math inline">\(T_{ij} =
\mathcal{T}(S_i \to S_j)\)</span> has an eigenvector with entries <span
class="math inline">\(P_i = P(S_i)\)</span> with eigenvalue 1 and all
other eigenvalues with magnitude less than one. The convergence time
depends on the magnitude of the second largest eigenvalue.</p>
<p>The choice of the transition function for MCMC is under-determined as
one only needs to satisfy a set of balance conditions for which there
are many solutions <span class="citation"
data-cites="kellyReversibilityStochasticNetworks1981"> [<a
href="#ref-kellyReversibilityStochasticNetworks1981"
role="doc-biblioref">7</a>]</span>. The standard choice that satisfies
these requirements is called the Metropolis-Hastings algorithm.</p>
</section>
<section id="the-metropolis-hastings-algorithm" class="level2">
<h2>The Metropolis-Hastings Algorithm</h2>
<p>The Metropolis-Hastings algorithm breaks the transition function into
a proposal distribution <span class="math inline">\(q(S \to
S&#39;)\)</span> and an acceptance function <span
class="math inline">\(\mathcal{A}(S \to S&#39;)\)</span>. <span
class="math inline">\(q\)</span> must be a function we can directly
sample from, and in many cases takes the form of flipping some number of
spins in <span class="math inline">\(S\)</span>, i.e if we’re flipping a
single random spin in the spin chain, <span class="math inline">\(q(S
\to S&#39;)\)</span> is the uniform distribution on states reachable by
one spin flip from <span class="math inline">\(S\)</span>. This also
gives the symmetry property that <span class="math inline">\(q(S \to
S&#39;) = q(S&#39; \to S)\)</span>.</p>
<p>The proposal <span class="math inline">\(S&#39;\)</span> is then
accepted or rejected with an acceptance probability <span
class="math inline">\(\mathcal{A}(S \to S&#39;)\)</span>, if the
proposal is rejected then <span class="math inline">\(S_{i+1} =
S_{i}\)</span>. Hence:</p>
<p><span class="math display">\[\mathcal{T}(S\to S&#39;) = q(S\to
S&#39;)\mathcal{A}(S \to S&#39;)\]</span></p>
<p>The Metropolis-Hasting algorithm is a slight extension of the
original Metropolis algorithm which allows for non-symmetric proposal
distributions $q(SS’) q(S’S) $. It can be derived starting from detailed
balance <span class="citation"
data-cites="krauthIntroductionMonteCarlo1998"> [<a
href="#ref-krauthIntroductionMonteCarlo1998"
role="doc-biblioref">6</a>]</span>:</p>
<p><span class="math display">\[
P(S)\mathcal{T}(S \to S&#39;) = P(S&#39;)\mathcal{T}(S&#39; \to S)
\]</span></p>
<p>inserting the proposal and acceptance function</p>
<p><span class="math display">\[
P(S)q(S \to S&#39;)\mathcal{A}(S \to S&#39;) = P(S&#39;)q(S&#39; \to
S)\mathcal{A}(S&#39; \to S)
\]</span></p>
<p>rearranging gives us a condition on the acceptance function in terms
of the target distribution and the proposal distribution which can be
thought of as inputs to the algorithm</p>
<p><span class="math display">\[
\frac{\mathcal{A}(S \to S&#39;)}{\mathcal{A}(S&#39; \to S)} =
\frac{P(S&#39;)q(S&#39; \to S)}{P(S)q(S \to S&#39;)} = f(S, S&#39;)
\]</span></p>
<p>The Metropolis-Hastings algorithm is the choice</p>
<p><span class="math display">\[
\begin{aligned}
\label{eq:mh}
\mathcal{A}(S \to S&#39;) = \min\left(1, f(S,S&#39;)\right)
\end{aligned}
\]</span> for the acceptance function. The proposal distribution is left
as a free choice.</p>
<p>Noting that <span class="math inline">\(f(S,S&#39;) =
1/f(S&#39;,S)\)</span>, we can see that the MH algorithm satifies
detailed balance by considering the two cases <span
class="math inline">\(f(S,S&#39;) &gt; 1\)</span> and <span
class="math inline">\(f(S,S&#39;) &lt; 1\)</span>.</p>
<p>By choosing the proposal distribution such that <span
class="math inline">\(f(S,S&#39;)\)</span> is as close as possible to
one, the rate of rejections can be reduced and the algorithm sped up.
This can be challenging though, as getting <span
class="math inline">\(f(S,S&#39;)\)</span> close to 1 would imply that
we can directly sample from a distribution very close to the target
distribution. As MCMC is usually applied to problems for which there is
virtually no hope of sampling directly from the target distribution,
it’s rare that one can do so approximately.</p>
<p>When the proposal distribution is symmetric as ours is, it cancels
out in the expression for the acceptance function and the
Metropolis-Hastings algorithm is simply the choice</p>
<p><span class="math display">\[\mathcal{A}(S \to S&#39;) = \min\left(1,
e^{-\beta\;\Delta F}\right)\]</span></p>
<p>where <span class="math inline">\(F\)</span> is the overall free
energy of the system, including both the quantum and classical
sector.</p>
</section>
<section id="implementation-of-the-mh-algorithm" class="level2">
<h2>Implementation of the MH Algorithm</h2>
<p>To implement the acceptance function in practice we pick a random
number in the unit interval and accept if it is less than <span
class="math inline">\(e^{-\beta\;\Delta F}\)</span>:</p>
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>current_state <span class="op">=</span> initial_state</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_steps):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    new_state <span class="op">=</span> proposal(current_state)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> free_energy_change(current_state, new_state, parameters)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&lt;</span> exp(<span class="op">-</span>beta <span class="op">*</span> df):</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>        current_state <span class="op">=</span> new_state</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>    states[i] <span class="op">=</span> current_state</span></code></pre></div>
</section>
<section id="the-metropolis-hasting-algorithm" class="level2">
<h2>The Metropolis-Hasting Algorithm</h2>
</section>
<section id="metropolis-hastings" class="level2">
<h2>Metropolis-Hastings</h2>
<p>In order to actually choose new states according to <span
class="math inline">\(\mathcal{T}\)</span> one chooses states from a
proposal distribution <span class="math inline">\(q(S_i \to
S&#39;)\)</span> that can be directly sampled from. For instance, this
might mean flipping a single random spin in a spin chain, in which case
<span class="math inline">\(q(x_i\to x_i)\)</span> is the uniform
distribution on states reachable by one spin flip from <span
class="math inline">\(x_i\)</span>. The proposal <span
class="math inline">\(S&#39;\)</span> is then accepted or rejected with
an acceptance probability <span class="math inline">\(\mathcal{A}(x_i\to
x_{i+1})\)</span>, if the proposal is rejected then <span
class="math inline">\(x_{i+1} = x_{i}\)</span>. Now <span
class="math inline">\(\mathcal{T}(S\to S&#39;) = q(S\to
S&#39;)\mathcal{A}(S \to S&#39;)\)</span>.</p>
<section id="the-metropolis-hastings-algorithm-1" class="level3">
<h3>The Metropolis-Hastings Algorithm</h3>
<p>MH breaks up the transition function into a proposal distribution
<span class="math inline">\(q(S \to S&#39;)\)</span> and an acceptance
function <span class="math inline">\(\mathcal{A}(S \to S&#39;)\)</span>.
<span class="math inline">\(q\)</span> needs to be something that we can
directly sample from, and in our case generally takes the form of
flipping some number of spins in <span class="math inline">\(S\)</span>,
i.e if we’re flipping a single random spin in the spin chain, <span
class="math inline">\(q(S \to S&#39;)\)</span> is the uniform
distribution on states reachable by one spin flip from <span
class="math inline">\(S\)</span>. This also gives the nice symmetry
property that <span class="math inline">\(q(S \to S&#39;) = q(S&#39; \to
S)\)</span>.</p>
<p>The proposal <span class="math inline">\(S&#39;\)</span> is then
accepted or rejected with an acceptance probability <span
class="math inline">\(\mathcal{A}(S \to S&#39;)\)</span>, if the
proposal is rejected then <span class="math inline">\(S_{i+1} =
S_{i}\)</span>. Hence:</p>
<p><span class="math display">\[\mathcal{T}(S\to S&#39;) = q(S\to
S&#39;)\mathcal{A}(S \to S&#39;)\]</span></p>
<p>When the proposal distribution is symmetric as ours is, it cancels
out in the expression for the acceptance function and the
Metropolis-Hastings algorithm is simply the choice: <span
class="math display">\[ \mathcal{A}(S \to S&#39;) = \min\left(1,
e^{-\beta\;\Delta F}\right)\]</span> Where <span
class="math inline">\(F\)</span> is the overall free energy of the
system, including both the quantum and classical sector.</p>
<p>To implement the acceptance function in practice we pick a random
number in the unit interval and accept if it is less than <span
class="math inline">\(e^{-\beta\;\Delta F}\)</span>:</p>
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>current_state <span class="op">=</span> initial_state</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_steps):</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>    new_state <span class="op">=</span> proposal(current_state)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>    df <span class="op">=</span> free_energy_change(current_state, new_state, parameters)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&lt;</span> exp(<span class="op">-</span>beta <span class="op">*</span> df):</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>        current_state <span class="op">=</span> new_state</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    states[i] <span class="op">=</span> current_state</span></code></pre></div>
<p>This has the effect of always accepting proposed states that are
lower in energy and sometimes accepting those that are higher in energy
than the current state.</p>
</section>
</section>
<section id="two-step-trick" class="level2">
<h2>Two Step Trick</h2>
<p>Our method already relies heavily on the split between the classical
and quantum sector to derive a sign problem free MCMC algorithm but it
turns out that there is a further trick we can play with it. The free
energy term is the sum of an easy to compute classical energy and a more
expensive quantum free energy, we can split the acceptance function into
two in such as way as to avoid having to compute the full exact
diagonalisation some of the time:</p>
<div class="sourceCode" id="cb4" data-language="Python"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>current_state <span class="op">=</span> initial_state</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_steps):</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    new_state <span class="op">=</span> proposal(current_state)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    df_classical <span class="op">=</span> classical_free_energy_change(current_state, new_state, parameters)</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> exp(<span class="op">-</span>beta <span class="op">*</span> df_classical) <span class="op">&lt;</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>        f_quantum <span class="op">=</span> quantum_free_energy(current_state, new_state, parameters)</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> exp(<span class="op">-</span> beta <span class="op">*</span> df_quantum) <span class="op">&lt;</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>):</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>          current_state <span class="op">=</span> new_state</span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>        states[i] <span class="op">=</span> current_state</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
</section>
<section id="detailed-balance-for-the-two-step-method" class="level2">
<h2>Detailed Balance for the two step method</h2>
<p>Given a MCMC algorithm with target distribution <span
class="math inline">\(\pi(a)\)</span> and transition function <span
class="math inline">\(\mathcal{T}\)</span> the detailed balance
condition is sufficient (along with some technical constraints <span
class="citation" data-cites="wolffMonteCarloErrors2004"> [<a
href="#ref-wolffMonteCarloErrors2004"
role="doc-biblioref">5</a>]</span>) to guarantee that in the long time
limit the algorithm produces samples from <span
class="math inline">\(\pi\)</span>. <span
class="math display">\[\pi(a)\mathcal{T}(a \to b) = \pi(b)\mathcal{T}(b
\to a)\]</span></p>
<p>In pseudo-code, our two step method corresponds to two nested
comparisons with the majority of the work only occurring if the first
test passes:</p>
<div class="sourceCode" id="cb5"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>current_state <span class="op">=</span> initial_state</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_steps):</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  new_state <span class="op">=</span> proposal(current_state)</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  c_dE <span class="op">=</span> classical_energy_change(</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>                               current_state,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>                               new_state)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&lt;</span> exp(<span class="op">-</span>beta <span class="op">*</span> c_dE):</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    q_dF <span class="op">=</span> quantum_free_energy_change(</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>                                current_state,</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>                                new_state)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&lt;</span> exp(<span class="op">-</span> beta <span class="op">*</span> q_dF):</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>      current_state <span class="op">=</span> new_state</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>    states[i] <span class="op">=</span> current_state</span></code></pre></div>
<p>Defining <span class="math inline">\(r_c = e^{-\beta H_c}\)</span>
and <span class="math inline">\(r_q = e^{-\beta F_q}\)</span> our target
distribution is <span class="math inline">\(\pi(a) = r_c r_q\)</span>.
This method has <span class="math inline">\(\mathcal{T}(a\to b) = q(a\to
b)\mathcal{A}(a \to b)\)</span> with symmetric <span
class="math inline">\(p(a \to b) = \pi(b \to a)\)</span> and <span
class="math inline">\(\mathcal{A} = \min\left(1, r_c\right) \min\left(1,
r_q\right)\)</span></p>
<p>Substituting this into the detailed balance equation gives: <span
class="math display">\[\mathcal{T}(a \to b)/\mathcal{T}(b \to a) =
\pi(b)/\pi(a) = r_c r_q\]</span></p>
<p>Taking the LHS and substituting in our transition function: <span
class="math display">\[\begin{aligned}
\mathcal{T}(a \to b)/\mathcal{T}(b \to a) = \frac{\min\left(1,
r_c\right) \min\left(1, r_q\right)}{ \min\left(1, 1/r_c\right)
\min\left(1, 1/r_q\right)}\end{aligned}\]</span></p>
<p>which simplifies to <span class="math inline">\(r_c r_q\)</span> as
<span class="math inline">\(\min(1,r)/\min(1,1/r) = r\)</span> for <span
class="math inline">\(r &gt; 0\)</span>.</p>
<section id="two-step-trick-1" class="level3">
<h3>Two Step Trick</h3>
<p>Our method already relies heavily on the split between the classical
and quantum sector to derive a sign problem free MCMC algorithm but it
turns out that there is a further trick we can play with it. The free
energy term is the sum of an easy to compute classical energy and a more
expensive quantum free energy, we can split the acceptance function into
two in such as way as to avoid having to compute the full exact
diagonalisation some of the time:</p>
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>current_state <span class="op">=</span> initial_state</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_steps):</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    new_state <span class="op">=</span> proposal(current_state)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>    df_classical <span class="op">=</span> classical_free_energy_change(current_state, new_state, parameters)</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> exp(<span class="op">-</span>beta <span class="op">*</span> df_classical) <span class="op">&lt;</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>):</span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>        f_quantum <span class="op">=</span> quantum_free_energy(current_state, new_state, parameters)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> exp(<span class="op">-</span> beta <span class="op">*</span> df_quantum) <span class="op">&lt;</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>):</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>          current_state <span class="op">=</span> new_state</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>        states[i] <span class="op">=</span> current_state</span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>    </span></code></pre></div>
</section>
<section id="auto-correlation-time" class="level3">
<h3>Auto-correlation Time</h3>
<div id="fig:m_autocorr" class="fignos">
<figure>
<img src="/assets/thesis/fk_chapter/lsr/figs/m_autocorr.png"
data-short-caption="no title" style="width:100.0%"
alt="Figure 1: (Upper) 10 MCMC chains starting from the same initial state for a system with N = 150 sites and 3000 MCMC steps. At each MCMC step, n spins are flipped where n is drawn from Uniform(1,N) and this is repeated N^2/100 times. The simulations therefore have the potential to necessitate 10*N^2 matrix diagonalisations for each 100 MCMC steps. (Lower) The normalised auto-correlation (\langle m_i m_{i-j}\rangle - \langle m_i\rangle \langle m_i \rangle) / Var(m_i)) averaged over i. It can be seen that even with each MCMC step already being composed of many individual flip attempts, the auto-correlation is still non negligible and must be taken into account in the statistics. t = 1, \alpha = 1.25, T = 2.2, J = U = 5" />
<figcaption aria-hidden="true"><span>Figure 1:</span> (Upper) 10 MCMC
chains starting from the same initial state for a system with <span
class="math inline">\(N = 150\)</span> sites and 3000 MCMC steps. At
each MCMC step, n spins are flipped where n is drawn from Uniform(1,N)
and this is repeated <span class="math inline">\(N^2/100\)</span> times.
The simulations therefore have the potential to necessitate <span
class="math inline">\(10*N^2\)</span> matrix diagonalisations for each
100 MCMC steps. (Lower) The normalised auto-correlation <span
class="math inline">\((\langle m_i m_{i-j}\rangle - \langle m_i\rangle
\langle m_i \rangle) / Var(m_i))\)</span> averaged over <span
class="math inline">\(i\)</span>. It can be seen that even with each
MCMC step already being composed of many individual flip attempts, the
auto-correlation is still non negligible and must be taken into account
in the statistics. <span class="math inline">\(t = 1, \alpha = 1.25, T =
2.2, J = U = 5\)</span></figcaption>
</figure>
</div>
<p>At this stage one might think we’re done. We can indeed draw
independent samples from <span class="math inline">\(P(S;
\beta)\)</span> by starting from some arbitrary initial state and doing
<span class="math inline">\(k\)</span> steps to arrive at a sample.
However a key insight is that after the convergence time, every state
generated is a sample from <span class="math inline">\(P(S;
\beta)\)</span>! They are not, however, independent samples. In Fig. ??
it is already clear that the samples of the order parameter m have some
auto-correlation because only a few spins are flipped each step but even
when the number of spins flipped per step is increased, Fig.
autocorrelation shows that it can be an important effect near the phase
transition. Let’s define the auto-correlation time <span
class="math inline">\(\tau(O)\)</span> informally as the number of MCMC
samples of some observable O that are statistically equal to one
independent sample or equivalently as the number of MCMC steps after
which the samples are correlated below some cut-off, see <span
class="citation" data-cites="krauthIntroductionMonteCarlo1996"> [<a
href="#ref-krauthIntroductionMonteCarlo1996"
role="doc-biblioref">9</a>]</span> for a more rigorous definition
involving a sum over the auto-correlation function. The auto-correlation
time is generally shorter than the convergence time so it therefore
makes sense from an efficiency standpoint to run a single walker for
many MCMC steps rather than to run a huge ensemble for <span
class="math inline">\(k\)</span> steps each.</p>
<p>Once the random walk has been carried out for many steps, the
expectation values of <span class="math inline">\(O\)</span> can be
estimated from the MCMC samples <span
class="math inline">\(S_i\)</span>: <span class="math display">\[
    \tex{O} = \sum_{i = 0}^{N} O(S_i) + \mathcal{O}(\frac{1}{\sqrt{N}})
\]</span></p>
<p>The the samples are correlated so the N of them effectively contains
less information than <span class="math inline">\(N\)</span> independent
samples would, in fact roughly <span
class="math inline">\(N/\tau\)</span> effective samples. As a
consequence the variance is larger than the <span
class="math inline">\(\qex{O^2} - \qex{O}^2\)</span> form it would have
if the estimates were uncorrelated. There are many methods in the
literature for estimating the true variance of <span
class="math inline">\(\qex{O}\)</span> and deciding how many steps are
needed but my approach has been to run a small number of parallel
chains, which are independent, in order to estimate the statistical
error produced. This is a slightly less computationally efficient
because it requires throwing away those <span
class="math inline">\(k\)</span> steps generated before convergence
multiple times but it is a conceptually simple workaround.</p>
<p>In summary, to do efficient simulations we want to reduce both the
convergence time and the auto-correlation time as much as possible. In
order to explain how, we need to introduce the Metropolis-Hasting (MH)
algorithm and how it gives an explicit form for the transition
function.</p>
</section>
<section id="tuning-the-proposal-distribution" class="level3">
<h3>Tuning the proposal distribution</h3>
<div id="fig:autocorr_multiple_proposals" class="fignos">
<figure>
<img
src="../figure_code/fk_chapter/lsr/figs/autocorr_multiple_proposals.png"
data-short-caption="no title" style="width:100.0%"
alt="Figure 2: Simulations showing how the autocorrelation of the order parameter depends on the proposal distribution used at different temperatures, we see that at T = 1.5 &lt; T_c a single spin flip is likely the best choice, while at the high temperature T = 2.5 &gt; T_c flipping two sites or a mixture of flipping two and 1 sites is likely a better choice. $t = 1, = 1.25, J = U = 5 $" />
<figcaption aria-hidden="true"><span>Figure 2:</span> Simulations
showing how the autocorrelation of the order parameter depends on the
proposal distribution used at different temperatures, we see that at
<span class="math inline">\(T = 1.5 &lt; T_c\)</span> a single spin flip
is likely the best choice, while at the high temperature <span
class="math inline">\(T = 2.5 &gt; T_c\)</span> flipping two sites or a
mixture of flipping two and 1 sites is likely a better choice. $t = 1, =
1.25, J = U = 5 $</figcaption>
</figure>
</div>
<p>Now we can discuss how to minimise the auto-correlations. The general
principle is that one must balance the proposal distribution between two
extremes. Choose overlay small steps, like flipping only a single spin
and the acceptance rate will be high because <span
class="math inline">\(\Delta F\)</span> will usually be small, but each
state will be very similar to the previous and the auto-correlations
will be high too, making sampling inefficient. On the other hand,
overlay large steps, like randomising a large portion of the spins each
step, will result in very frequent rejections, especially at low
temperatures.</p>
<p>I evaluated a few different proposal distributions for use with the
FK model.</p>
<ol type="1">
<li>Flipping a single random site</li>
<li>Flipping N random sites for some N</li>
<li>Choosing n from Uniform(1, N) and then flipping n sites for some
fixed N.</li>
<li>Attempting to tune the proposal distribution for each parameter
regime.</li>
</ol>
<p>Fro Figure~<span class="math inline">\(\ref{fig:comparison}\)</span>
we see that even at moderately high temperatures <span
class="math inline">\(T &gt; T_c\)</span> flipping one or two sites is
the best choice. However for some simulations at very high temperature
flipping more spins is warranted. Tuning the proposal distribution
automatically seems like something that would not yield enough benefit
for the additional complexity it would require.</p>
</section>
</section>
<section id="proposal-distributions" class="level2">
<h2>Proposal Distributions</h2>
<p>In a MCMC method a key property is the proportion of the time that
proposals are accepted, the acceptance rate. If this rate is too low the
random walk is trying to take overly large steps in energy space which
problematic because it means very few new samples will be generated. If
it is too high it implies the steps are too small, a problem because
then the walk will take longer to explore the state space and the
samples will be highly correlated. Ideal values for the acceptance rate
can be calculated under certain assumptions <span class="citation"
data-cites="robertsWeakConvergenceOptimal1997"> [<a
href="#ref-robertsWeakConvergenceOptimal1997"
role="doc-biblioref">10</a>]</span>. Here we monitor the acceptance rate
and if it is too high we re-run the MCMC with a modified proposal
distribution that has a chance to propose moves that flip multiple sites
at a time.</p>
<p>In addition we exploit the particle-hole symmetry of the problem by
occasionally proposing a flip of the entire state. This works because
near half-filling, flipping the occupations of all the sites will
produce a state at or near the energy of the current one.</p>
</section>
<section id="choosing-the-proposal-distribution" class="level2">
<h2>Choosing the proposal distribution</h2>
<p><img src="figs/lsr/autocorr_multiple_proposals.png" title="fig:"
id="fig:comparison"
alt="t = 1, \alpha = 1.25, J = U = 5 [fig:comparison]" /> Simulations
showing how the autocorrelation of the order parameter depends on the
proposal distribution used at different temperatures, we see that at
<span class="math inline">\(T = 1.5 &lt; T_c\)</span> a single spin flip
is likely the best choice, while at the high temperature <span
class="math inline">\(T = 2.5 &gt; T_c\)</span> flipping two sites or a
mixture of flipping two and 1 sites is likely a better choice.</p>
<p>Now we can discuss how to minimise the auto-correlations. The general
principle is that one must balance the proposal distribution between two
extremes. Choose overlay small steps, like flipping only a single spin
and the acceptance rate will be high because <span
class="math inline">\(\Delta F\)</span> will usually be small, but each
state will be very similar to the previous and the auto-correlations
will be high too, making sampling inefficient. On the other hand,
overlay large steps, like randomising a large portion of the spins each
step, will result in very frequent rejections, especially at low
temperatures.</p>
<p>I evaluated a few different proposal distributions for use with the
FK model.</p>
<ol type="1">
<li><p>Flipping a single random site</p></li>
<li><p>Flipping N random sites for some N</p></li>
<li><p>Choosing n from Uniform(1, N) and then flipping n sites for some
fixed N.</p></li>
<li><p>Attempting to tune the proposal distribution for each parameter
regime.</p></li>
</ol>
<p>Fro Figure <a href="#fig:comparison" data-reference-type="ref"
data-reference="fig:comparison">4</a> we see that even at moderately
high temperatures <span class="math inline">\(T &gt; T_c\)</span>
flipping one or two sites is the best choice. However for some
simulations at very high temperature flipping more spins is warranted.
Tuning the proposal distribution automatically seems like something that
would not yield enough benefit for the additional complexity it would
require.</p>
</section>
<section id="perturbation-mcmc" class="level2">
<h2>Perturbation MCMC</h2>
<p>The matrix diagonalisation is the most computationally expensive step
of the process, a speed up can be obtained by modifying the proposal
distribution to depend on the classical part of the energy, a trick
gleaned from Ref. <span class="citation"
data-cites="krauthIntroductionMonteCarlo1998"> [<a
href="#ref-krauthIntroductionMonteCarlo1998"
role="doc-biblioref">6</a>]</span>: <span class="math display">\[
\begin{aligned}
q(k \to k&#39;) &amp;= \min\left(1, e^{\beta (H^{k&#39;} - H^k)}\right)
\\
\mathcal{A}(k \to k&#39;) &amp;= \min\left(1, e^{\beta(F^{k&#39;}-
F^k)}\right)
\end{aligned}\]</span> % This allows the method to reject some states
without performing the diagonalisation at no cost to the accuracy of the
MCMC method.</p>
<p>An extension of this idea is to try to define a classical model with
a similar free energy dependence on the classical state as the full
quantum, Ref. <span class="citation"
data-cites="huangAcceleratedMonteCarlo2017"> [<a
href="#ref-huangAcceleratedMonteCarlo2017"
role="doc-biblioref">11</a>]</span> does this with restricted Boltzmann
machines whose form is very similar to a classical spin model.</p>
<section id="convergence-time" class="level3">
<h3>Convergence Time</h3>
<p>Considering <span class="math inline">\(p(S)\)</span> as a vector
<span class="math inline">\(\vec{p}\)</span> whose jth entry is the
probability of the jth state <span class="math inline">\(p_j =
p(S_j)\)</span>, and writing <span
class="math inline">\(\mathcal{T}\)</span> as the matrix with entries
<span class="math inline">\(T_{ij} = \mathcal{T}(S_j \rightarrow
S_i)\)</span> we can write the update rule for the ensemble probability
as: <span class="math display">\[\vec{p}_{t+1} = \mathcal{T} \vec{p}_t
\implies \vec{p}_{t} = \mathcal{T}^t \vec{p}_0\]</span> where <span
class="math inline">\(\vec{p}_0\)</span> is vector which is one on the
starting state and zero everywhere else. Since all states must
transition to somewhere with probability one: <span
class="math inline">\(\sum_i T_{ij} = 1\)</span>.</p>
<p>Matrices that satisfy this are called stochastic matrices exactly
because they model these kinds of Markov processes. It can be shown that
they have real eigenvalues, and ordering them by magnitude, that <span
class="math inline">\(\lambda_0 = 1\)</span> and <span
class="math inline">\(0 &lt; \lambda_{i\neq0} &lt; 1\)</span>.
%https://en.wikipedia.org/wiki/Stochastic_matrix</p>
<p>Assuming <span class="math inline">\(\mathcal{T}\)</span> has been
chosen correctly, its single eigenvector with eigenvalue 1 will be the
thermal distribution so repeated application of the transition function
eventually leads there, while memory of the initial conditions decays
exponentially with a convergence time <span
class="math inline">\(k\)</span> determined by <span
class="math inline">\(\lambda_1\)</span>. In practice this means that
one throws away the data from the beginning of the random walk in order
reduce the dependence on the initial conditions and be close enough to
the target distribution.</p>
</section>
</section>
</section>
<section id="appbalance-detailed-balance" class="level1">
<h1><span id="app:balance" label="app:balance">[app:balance]</span>
DETAILED BALANCE</h1>
<p>Given a <span data-acronym-label="MCMC"
data-acronym-form="singular+short">MCMC</span> algorithm with target
distribution <span class="math inline">\(\pi(a)\)</span> and transition
function <span class="math inline">\(\T\)</span> the detailed balance
condition is sufficient (along with some technical constraints <span
class="citation" data-cites="wolffMonteCarloErrors2004"> [<a
href="#ref-wolffMonteCarloErrors2004"
role="doc-biblioref">5</a>]</span>) to guarantee that in the long time
limit the algorithm produces samples from <span
class="math inline">\(\pi\)</span>. <span
class="math display">\[\pi(a)\T(a \to b) = \pi(b)\T(b \to
a)\]</span></p>
<p>In pseudo-code, our two step method corresponds to two nested
comparisons with the majority of the work only occurring if the first
test passes:</p>
<div class="sourceCode" id="cb7"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>current_state <span class="op">=</span> initial_state</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i <span class="kw">in</span> <span class="bu">range</span>(N_steps):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>  new_state <span class="op">=</span> proposal(current_state)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>  c_dE <span class="op">=</span> classical_energy_change(</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>                               current_state,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>                               new_state)</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">if</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&lt;</span> exp(<span class="op">-</span>beta <span class="op">*</span> c_dE):</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    q_dF <span class="op">=</span> quantum_free_energy_change(</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>                                current_state,</span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>                                new_state)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> uniform(<span class="dv">0</span>,<span class="dv">1</span>) <span class="op">&lt;</span> exp(<span class="op">-</span> beta <span class="op">*</span> q_dF):</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>      current_state <span class="op">=</span> new_state</span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    states[i] <span class="op">=</span> current_state</span></code></pre></div>
<p>Defining <span class="math inline">\(r_c = e^{-\beta H_c}\)</span>
and <span class="math inline">\(r_q = e^{-\beta F_q}\)</span> our target
distribution is <span class="math inline">\(\pi(a) = r_c r_q\)</span>.
This method has <span class="math inline">\(\T(a\to b) = q(a\to b)\A(a
\to b)\)</span> with symmetric <span class="math inline">\(p(a \to b) =
\p(b \to a)\)</span> and <span class="math inline">\(\A = \min\left(1,
r_c\right) \min\left(1, r_q\right)\)</span></p>
<p>Substituting this into the detailed balance equation gives: <span
class="math display">\[\T(a \to b)/\T(b \to a) = \pi(b)/\pi(a) = r_c
r_q\]</span></p>
<p>Taking the LHS and substituting in our transition function: <span
class="math display">\[\begin{aligned}
\T(a \to b)/\T(b \to a) = \frac{\min\left(1, r_c\right) \min\left(1,
r_q\right)}{ \min\left(1, 1/r_c\right) \min\left(1,
1/r_q\right)}\end{aligned}\]</span></p>
<p>which simplifies to <span class="math inline">\(r_c r_q\)</span> as
<span class="math inline">\(\min(1,r)/\min(1,1/r) = r\)</span> for <span
class="math inline">\(r &gt; 0\)</span>.</p>
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"></code></pre></div>
</section>
<section id="bibliography" class="level1 unnumbered">
<h1 class="unnumbered">Bibliography</h1>
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-devroyeRandomSampling1986" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[1] </div><div class="csl-right-inline">L.
Devroye, <em><a
href="https://doi.org/10.1007/978-1-4613-8643-8_12">Random
Sampling</a></em>, in <em>Non-Uniform Random Variate Generation</em>,
edited by L. Devroye (Springer, New York, NY, 1986), pp. 611–641.</div>
</div>
<div id="ref-BMCP2021" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">[2] </div><div class="csl-right-inline">O.
A. Martin, R. Kumar, and J. Lao, <em>Bayesian Modeling and Computation
in Python</em> (Boca Raton, 2021).</div>
</div>
<div id="ref-binderGuidePracticalWork1988" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[3] </div><div class="csl-right-inline">K.
Binder and D. W. Heermann, <em><a
href="https://doi.org/10.1007/978-3-662-08854-8_3">Guide to Practical
Work with the Monte Carlo Method</a></em>, in <em>Monte Carlo Simulation
in Statistical Physics: An Introduction</em>, edited by K. Binder and D.
W. Heermann (Springer Berlin Heidelberg, Berlin, Heidelberg, 1988), pp.
68–112.</div>
</div>
<div id="ref-kerteszAdvancesComputerSimulation1998" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[4] </div><div class="csl-right-inline">J.
Kertesz and I. Kondor, editors, <em><a
href="https://doi.org/10.1007/BFb0105456">Advances in Computer
Simulation: Lectures Held at the Eötvös Summer School in Budapest,
Hungary, 16–20 July 1996</a></em> (Springer-Verlag, Berlin Heidelberg,
1998).</div>
</div>
<div id="ref-wolffMonteCarloErrors2004" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[5] </div><div class="csl-right-inline">U.
Wolff, <em><a href="https://doi.org/10.1016/S0010-4655(03)00467-3">Monte
Carlo Errors with Less Errors</a></em>, Computer Physics Communications
<strong>156</strong>, 143 (2004).</div>
</div>
<div id="ref-krauthIntroductionMonteCarlo1998" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[6] </div><div class="csl-right-inline">W.
Krauth, <em><a href="https://doi.org/10.1007/BFb0105456">Introduction To
Monte Carlo Algorithms</a></em>, in <em>Advances in Computer Simulation:
Lectures Held at the Eötvös Summer School in Budapest, Hungary, 16–20
July 1996</em> (Springer-Verlag, Berlin Heidelberg, 1998).</div>
</div>
<div id="ref-kellyReversibilityStochasticNetworks1981" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[7] </div><div class="csl-right-inline">F.
P. Kelly, <em><a href="https://doi.org/10.2307/2287860">Reversibility
and Stochastic Networks / F.P. Kelly</a></em>, SERBIULA (Sistema Librum
2.0) <strong>76</strong>, (1981).</div>
</div>
<div id="ref-kapferSamplingPolytopeHarddisk2013" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[8] </div><div class="csl-right-inline">S.
C. Kapfer and W. Krauth, <em><a
href="https://doi.org/10.1088/1742-6596/454/1/012031">Sampling from a
Polytope and Hard-Disk Monte Carlo</a></em>, J. Phys.: Conf. Ser.
<strong>454</strong>, 012031 (2013).</div>
</div>
<div id="ref-krauthIntroductionMonteCarlo1996" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[9] </div><div class="csl-right-inline">W.
Krauth, <em><a href="http://arxiv.org/abs/cond-mat/9612186">Introduction
To Monte Carlo Algorithms</a></em>, arXiv:cond-Mat/9612186 (1996).</div>
</div>
<div id="ref-robertsWeakConvergenceOptimal1997" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[10] </div><div class="csl-right-inline">G.
O. Roberts, A. Gelman, and W. R. Gilks, <em><a
href="https://doi.org/10.1214/aoap/1034625254">Weak Convergence and
Optimal Scaling of Random Walk Metropolis Algorithms</a></em>, Ann.
Appl. Probab. <strong>7</strong>, 110 (1997).</div>
</div>
<div id="ref-huangAcceleratedMonteCarlo2017" class="csl-entry"
role="doc-biblioentry">
<div class="csl-left-margin">[11] </div><div class="csl-right-inline">L.
Huang and L. Wang, <em><a
href="https://doi.org/10.1103/PhysRevB.95.035105">Accelerated Monte
Carlo Simulations with Restricted Boltzmann Machines</a></em>, Phys.
Rev. B <strong>95</strong>, 035105 (2017).</div>
</div>
</div>
</section>


</main>
</body>
</html>
